{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f053ebd2",
   "metadata": {},
   "source": [
    "# Autocalibration ideas based on current implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6392a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from collections.abc import Callable, Sequence, Iterator, Mapping\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes\n",
    "import hist\n",
    "\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "\n",
    "import scipy\n",
    "\n",
    "from lgdo import lh5\n",
    "from lgdo.lh5.exceptions import LH5DecodeError\n",
    "from legendmeta import LegendMetadata\n",
    "from dspeed.processors import get_multi_local_extrema\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "\n",
    "proj_dir = \"/mnt/atlas02/projects/legend/sipm_qc\"\n",
    "lmeta  = LegendMetadata(os.path.join(proj_dir, \"metadata/legend-metadata-schwarz\"))\n",
    "chmap = lmeta.channelmap(\"20250807T150028Z\")\n",
    "chmap_sipm = chmap.map(\"system\", unique=False).spms\n",
    "#requires recent legend-datasets\n",
    "raw_keys = chmap_sipm.map(\"analysis.usability\", unique=False).on.map(\"daq.rawid\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b39e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = os.path.join(proj_dir, \"data/tier/raw/phy/p15/r004_part\")\n",
    "dsp_dir = os.path.join(proj_dir, \"manual_dsp/generated/p15r004dsp_part\")\n",
    "orig_dsp_dir = os.path.join(proj_dir, \"data/tier/dsp/phy/p15/r004\")\n",
    "dsp_files = glob.glob(dsp_dir+\"/l200-*-tier_dsp.lh5\")\n",
    "dsp_files.sort()\n",
    "def gimme_raw_filename_from_dsp(dspfilename: str):\n",
    "    return dspfilename.replace(dsp_dir, raw_dir).replace(\"tier_dsp\", \"tier_raw\")\n",
    "def gimme_orig_dsp_filename(dspfilename: str):\n",
    "    # get the original dsp files so I get pulser info\n",
    "    return dspfilename.replace(dsp_dir, orig_dsp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nopulser_mask(orig_dsp_file: Sequence[str] | str) -> ak.Array:\n",
    "    trap_puls = lh5.read_as(f\"ch{chmap['PULS01'].daq.rawid}/dsp/trapTmax\", orig_dsp_file, \"ak\")\n",
    "    return trap_puls < 100\n",
    "\n",
    "#trap_puls = lh5.read_as(f\"ch{chmap['PULS01'].daq.rawid}/dsp/trapTmax\", f_dsp, \"np\")\n",
    "#selection = trap_puls < 100\n",
    "#idx_not_pulser = np.where(selection)[0]\n",
    "#idx_pulser = np.where(~selection)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_some_wfs(wfs, ax, num=10):\n",
    "    \n",
    "    if wfs.shape[0] < num:\n",
    "        num = wfs.shape[0]\n",
    "        \n",
    "    t = np.arange(0, wfs.shape[1]*0.016, 0.016)\n",
    "    \n",
    "    for i in range(num):\n",
    "        t = np.arange(0, len(wfs[i])*0.016, 0.016)\n",
    "        ax.plot(t, wfs[i])\n",
    "        \n",
    "    ax.set_xlabel(\"Time (Âµs)\")\n",
    "    ax.set_ylabel(\"ADC counts / sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1760b",
   "metadata": {},
   "source": [
    "# Check uncalibrated spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ef145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energies(dsp_file: Sequence[str] | str, keys: Iterator[int], chmap, *, \n",
    "                 orig_dsp_file: Sequence[str] | str | None = None):\n",
    "    \"\"\"if orig_dsp_file is given: remove the pulser based on get_nopulser_mask\"\"\"\n",
    "    keys: list[int] = list(keys) # I need to access element 0 separately\n",
    "\n",
    "    def get_energy_object_name_function(dsp_file: str, raw_key: int, name_key: str) -> Callable[[int, str], str]:\n",
    "        if not os.path.isfile(dsp_file):\n",
    "            raise RuntimeError(f\"ERROR: no file: {dsp_file}\")\n",
    "        fcns = [lambda rawid, name: f\"ch{rawid}/dsp/energy\", lambda rawid, name: f\"ch{rawid}/dsp/energies\",\n",
    "                lambda rawid, name: f\"{name}/dsp/energy\", lambda rawid, name: f\"{name}/dsp/energies\"]\n",
    "        for fcn in fcns:\n",
    "            try:\n",
    "                _ = lh5.read_as(fcn(raw_key, name_key), dsp_file, \"ak\")\n",
    "                return fcn\n",
    "            except LH5DecodeError:\n",
    "                continue\n",
    "        raise RuntimeError(\"Have no clue how to extract energy info\")\n",
    "\n",
    "    energy_object_name_fcn = get_energy_object_name_function(dsp_file if isinstance(dsp_file, str) else dsp_file[0], keys[0], chmap.map(\"daq.rawid\")[keys[0]].name)\n",
    "    energies_dict = {}\n",
    "    #print(f\"{len(keys)} keys in dsp files\")\n",
    "    for ch in keys:\n",
    "        name = chmap.map(\"daq.rawid\")[ch].name\n",
    "        #energy = lh5.read_as(f\"{name}/dsp/energy\", f_dsp, \"ak\")\n",
    "        energy = lh5.read_as(energy_object_name_fcn(ch, name), dsp_file, \"ak\")\n",
    "        # remove pulser if we have original DSP files (containing pulser info)\n",
    "        # TODO perf: cache nopulser_mask\n",
    "        if orig_dsp_file is not None:\n",
    "            nopulser_mask = get_nopulser_mask(orig_dsp_file)\n",
    "            if len(nopulser_mask) < len(energy):\n",
    "                raise RuntimeError(\"Nopulser mask too short\")\n",
    "            elif len(nopulser_mask) > len(energy):\n",
    "                nopulser_mask = nopulser_mask[:len(energy)]\n",
    "            energy = energy[nopulser_mask]\n",
    "\n",
    "        energies = np.array(ak.flatten(energy))\n",
    "\n",
    "        energies_dict[name] = energies\n",
    "        \n",
    "    energies_dict = dict(sorted(energies_dict.items()))\n",
    "    \n",
    "    return energies_dict\n",
    "\n",
    "\n",
    "def gen_hist_by_quantile(data, quantile=0.99, nbins=200):\n",
    "    bins = np.linspace(0, np.round(np.quantile(data, quantile)), nbins+1)\n",
    "    n, be = np.histogram(data, bins)\n",
    "    return n, be\n",
    "\n",
    "def gen_hist_by_range(data, range, nbins=200):\n",
    "    n, be = np.histogram(data, range=range, bins=nbins)\n",
    "    return n, be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86836a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_pe_spectra(energies_dict) -> Figure:\n",
    "    fig, ax = plt.subplots(10, 6, figsize=(20,20))\n",
    "    ax = ax.ravel()\n",
    "    for i, (name, data) in enumerate(energies_dict.items()):\n",
    "        n, be = gen_hist_by_quantile(data, 0.96)\n",
    "        ax[i].stairs(n, be)\n",
    "        ax[i].set_yscale(\"log\")\n",
    "        ax[i].set_title(name, fontsize=10)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_all_pe_histograms(histos: dict[str, dict[str, Any]], *, gridx = False) -> Figure:\n",
    "    fig, ax = plt.subplots(10, 6, figsize=(20, 20))\n",
    "    ax = ax.ravel()\n",
    "    for i, (name, histo) in enumerate(histos.items()):\n",
    "        ax[i].set_yscale('log')\n",
    "        ax[i].stairs(histo[\"n\"], histo[\"be\"])\n",
    "        ax[i].set_title(name)\n",
    "        if gridx:\n",
    "            ax[i].grid(axis='x')\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fdee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = get_energies(dsp_files, raw_keys, chmap, orig_dsp_file=[gimme_orig_dsp_filename(dsp) for dsp in dsp_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a79aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "ax.stairs(*gen_hist_by_range(get_energies(dsp_files, raw_keys, chmap)[\"S002\"], (0,50)))\n",
    "ax.stairs(*gen_hist_by_range(get_energies(list(map(gimme_orig_dsp_filename, dsp_files)), raw_keys, chmap)[\"S002\"], (0,50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7266fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_all_pe_spectra(get_energies(gimme_orig_dsp_filename(dsp_files[0]), list(raw_keys), chmap))\n",
    "#plot_all_pe_spectra(get_energies(list(map(gimme_orig_dsp_filename, dsp_files)), list(raw_keys), chmap))\n",
    "_ = plot_all_pe_spectra(energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11163786",
   "metadata": {},
   "source": [
    "# Simple calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0db901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default inputs\n",
    "peakfinder_defaults = {\n",
    "    \"a_delta_min_in\": 5e-3,\n",
    "    \"a_delta_max_in\": 5e-3,\n",
    "    \"search_direction\": 3,\n",
    "    \"a_abs_min_in\": 1000,\n",
    "    \"a_abs_max_in\": 1e-4,\n",
    "    \"min_peak_dist\": 6,\n",
    "    \"peakdist_compare_margin\": 1,\n",
    "    \"strict\": True\n",
    "}\n",
    "    \n",
    "def find_pe_peaks_in_hist(n, be, params: Mapping[str, Any]) -> np.typing.NDArray[np.int_]:\n",
    "    n = np.array(n)\n",
    "    be = np.array(be)\n",
    "\n",
    "    # Outputs\n",
    "    vt_max_out = np.zeros(shape=len(n) - 1)\n",
    "    vt_min_out = np.zeros(shape=len(n) - 1)\n",
    "    n_max_out = 0\n",
    "    n_min_out = 0\n",
    "\n",
    "    # Call the function with updated parameters\n",
    "    get_multi_local_extrema(\n",
    "        n,\n",
    "        params[\"a_delta_max_in\"] * np.max(n),\n",
    "        params[\"a_delta_min_in\"] * np.max(n),\n",
    "        params[\"search_direction\"],\n",
    "        params[\"a_abs_max_in\"] * np.max(n),\n",
    "        params[\"a_abs_min_in\"] * np.max(n),\n",
    "        vt_max_out,\n",
    "        vt_min_out,\n",
    "        n_max_out,\n",
    "        n_min_out,\n",
    "    ) # type: ignore\n",
    "\n",
    "    peakpos_indices = vt_max_out[~np.isnan(vt_max_out)].astype(np.int_)\n",
    "    return peakpos_indices\n",
    "\n",
    "class ResultCheckError(ValueError):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(*args)\n",
    "\n",
    "def check_and_improve_PE_peaks(\n",
    "        peakpos_indices: np.typing.NDArray[np.int_], \n",
    "        n: np.typing.NDArray[Any],\n",
    "        be: np.typing.NDArray[Any],\n",
    "        params: Mapping[str, Any]\n",
    "        ) -> tuple[np.typing.NDArray[np.int_], dict[int, list[Any]]]:\n",
    "    \"\"\"\n",
    "    Checks and improves the indices of detected photoelectron (PE) peaks in a histogram.\n",
    "    Applies strict or non-strict validation rules to ensure the peaks correspond to expected\n",
    "    noise and PE peaks, and optionally handles double-peak SiPMs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peakpos_indices : np.typing.NDArray[np.int_]\n",
    "    Indices of detected peaks in the histogram.\n",
    "    n : np.typing.NDArray[Any]\n",
    "    Histogram bin counts.\n",
    "    be : np.typing.NDArray[Any]\n",
    "    Histogram bin edges.\n",
    "    params : Mapping[str, Any]\n",
    "    Dictionary of peak finding and checking parameters. Keys include:\n",
    "        - \"double_peak\": bool, whether to handle double-peak SiPMs.\n",
    "        - \"min_peak_dist\": int, minimum distance between peaks (in bins).\n",
    "        - \"strict\": bool, whether to apply strict validation.\n",
    "        - \"peakdist_compare_margin\": int, margin for peak distance comparison.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np.typing.NDArray[np.int_], dict[int, list[Any]]]\n",
    "    Validated and possibly improved peak indices, and a mapping of peak indices to \n",
    "    all bin edge values (i.e. two values for 1PE peak if double peak)\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ResultCheckError\n",
    "    If validation fails under strict mode or insufficient peaks are found.\n",
    "    \"\"\"\n",
    "    if params.get(\"double_peak\", False):\n",
    "        if len(peakpos_indices) < 3:\n",
    "            raise ResultCheckError(f\"Require at least 3 found peaks for double-peak SiPMs; found only {len(peakpos_indices)}.\")\n",
    "        peakpos_map = {0: [be[peakpos_indices[0]]], 1: [be[peakpos_indices[1]], be[peakpos_indices[2]]]} | {i: [be[peakpos_indices[i+1]]] for i in range(2, len(peakpos_indices)-1)}\n",
    "        mean_1_2 = (peakpos_indices[1] + peakpos_indices[2]) // 2 # small bias but ok\n",
    "        peakpos_indices = np.concatenate((np.array([peakpos_indices[0], mean_1_2], dtype=np.int_), peakpos_indices[3:]))\n",
    "    else:\n",
    "        peakpos_map = {i: [be[peakpos_indices[i]]] for i in range(0, len(peakpos_indices))}\n",
    "\n",
    "    min_peak_dist = params[\"min_peak_dist\"]\n",
    "    if params[\"strict\"]:\n",
    "        if len(peakpos_indices) < 2:\n",
    "            raise ResultCheckError(f\"Only {len(peakpos_indices)} peaks found. Either noise peak or 1pe peak not found.\")\n",
    "\n",
    "        if n[peakpos_indices[1]] > n[peakpos_indices[0]]:\n",
    "            raise ResultCheckError(f\"1pe peak larger than noise peak.\")\n",
    "\n",
    "        if peakpos_indices[1] - peakpos_indices[0] < min_peak_dist:\n",
    "            raise ResultCheckError(f\"Noise peak and 1pe peak too close together (< {min_peak_dist} bins).\")\n",
    "\n",
    "        if len(peakpos_indices) > 2:\n",
    "            if peakpos_indices[2] - peakpos_indices[1] < min_peak_dist:\n",
    "                raise ResultCheckError(f\"1pe peak and 2pe peak too close together (< {min_peak_dist} bins).\")\n",
    "            if (peakpos_indices[2] - peakpos_indices[1] + params[\"peakdist_compare_margin\"]) < peakpos_indices[1] - peakpos_indices[0]:\n",
    "                raise ResultCheckError(f\"Distance between 1pe and 2pe smaller than 0pe and 1pe (outside peakdist_compare_margin of {params[\"peakdist_compare_margin\"]}).\")\n",
    "    else:\n",
    "        if len(peakpos_indices) > 2:\n",
    "            if peakpos_indices[2] - peakpos_indices[1] < min_peak_dist:\n",
    "                print(f\"1pe peak and 2pe peak too close together (< {min_peak_dist} bins). Removing '1pe' peak.\")\n",
    "                peakpos_indices = peakpos_indices[peakpos_indices != peakpos_indices[1]]\n",
    "    return  peakpos_indices, peakpos_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_calibration(energies, gen_hist_params: Mapping[str, Any], \n",
    "                       peakfinder_params: Mapping[str, Any],\n",
    "                       calibration_params: Mapping[str, Any], *, \n",
    "                       ax = None, verbosity = 0) -> dict[str, float | dict[int, list[Any]]]:\n",
    "    \"\"\"Generate histogram and perform a simple peakfinder-based calibration. \n",
    "    If an axis is provided: plot on that (otherwise don't plot)\n",
    "    Does this for 1 SiPM; i.e. energies has to be a 1-d array of energies\n",
    "    Returns calibration and dict of PE-indices to list of peak positions (in a.u.) found for these\"\"\"\n",
    "    match gen_hist_params:\n",
    "        case {\"quantile\": quantile, \"nbins\": nbins}:\n",
    "            n, be = gen_hist_by_quantile(energies, quantile, nbins)\n",
    "        case {\"range\": r, \"nbins\": nbins}:\n",
    "            n, be = gen_hist_by_range(energies, r, nbins)\n",
    "        case _:\n",
    "            raise TypeError(\"gen_hist_params does not match valid histogram type\")\n",
    "    peakpos_indices = find_pe_peaks_in_hist(n, be, peakfinder_params)\n",
    "    failed_checks = False\n",
    "    try:\n",
    "        peakpos_indices, peakpos_map = check_and_improve_PE_peaks(peakpos_indices, n, be, peakfinder_params)\n",
    "    except ResultCheckError:\n",
    "        failed_checks = True\n",
    "        peaks = be[peakpos_indices] # use old indices for peaks\n",
    "        raise # runs finally before raise\n",
    "    else: \n",
    "        peaks = be[peakpos_indices]\n",
    "\n",
    "        if len(peaks) > 2: # use 1PE and 2PE\n",
    "            gain = peaks[2] - peaks[1]\n",
    "            c = 1/gain\n",
    "            offset = 1 - peaks[1] * c # 1pe peak at 1\n",
    "        else: \n",
    "            if calibration_params.get(\"use_1pe_0pe_diff_as_fallback\", False):\n",
    "                # fallback: use 0 PE and 1 PE - DISCOURAGED because distance usually too small!\n",
    "                gain = peaks[1] - peaks[0]\n",
    "                c = 1/gain\n",
    "                offset = 1 - peaks[1] * c # 1pe peak at 1   \n",
    "            else:\n",
    "                # fallback: use only position of 1 PE\n",
    "                gain = peaks[1]\n",
    "                c = 1/gain\n",
    "                offset = 0\n",
    "\n",
    "        # runs finally (i.e. plot) before return\n",
    "        return {\"slope\": c, \"offset\": offset, \"peaks\": peakpos_map}\n",
    "    finally: # draw in any case (for debugging); but choose color\n",
    "         if ax is not None:\n",
    "            hist_color = \"red\" if failed_checks else \"blue\"\n",
    "            line_color = \"grey\" if failed_checks else \"red\"\n",
    "            # uncalibrated histogram and peaks\n",
    "            ax.stairs(n, be, color=hist_color)\n",
    "            for p in peaks: # type: ignore\n",
    "                ax.axvline(x=p, color=line_color, ls=\":\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f984d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_simple_calibration(energies_dict, \n",
    "                             gen_hist_defaults: dict[str, Any], \n",
    "                             peakfinder_defaults: dict[str, Any],\n",
    "                             calibration_defaults: dict[str, Any], *,\n",
    "                             gen_hist_overrides: dict[str, dict[str, Any]] = {}, \n",
    "                             peakfinder_overrides: dict[str, dict[str, Any]] = {},\n",
    "                             calibration_overrides: dict[str, dict[str, Any]] = {},\n",
    "                             draw = False, \n",
    "                             nodraw_axes = False, \n",
    "                             verbosity = 0\n",
    "                             ) -> tuple[dict[str, dict[str, float]], int, Figure | None]:\n",
    "    \"\"\"Performs simple_calibration for all channels present in energies_dict\"\"\"\n",
    "    ret = {}\n",
    "    fig = None\n",
    "    if draw:\n",
    "        fig, ax = plt.subplots(10, 6, figsize=(20,20))\n",
    "        ax_iter = iter(ax.ravel())\n",
    "    nr_unsuccessful_calibs = 0\n",
    "    for name, energies in energies_dict.items():\n",
    "        if draw:\n",
    "            ax = next(ax_iter)\n",
    "            ax.set_yscale(\"log\")\n",
    "            if nodraw_axes:\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "            ax.set_title(name, fontsize=10)\n",
    "        else:\n",
    "            ax = None\n",
    "        try:\n",
    "            calib_results = simple_calibration(\n",
    "                energies,\n",
    "                gen_hist_defaults | gen_hist_overrides.get(name, {}),\n",
    "                peakfinder_defaults | peakfinder_overrides.get(name, {}),\n",
    "                calibration_defaults | calibration_overrides.get(name, {}),\n",
    "                ax=ax,  verbosity=verbosity)\n",
    "            ret[name] = calib_results\n",
    "        except ResultCheckError as e:\n",
    "            print(f\"Calibration failed for {name}: {e}\")\n",
    "            ret[name] = {\"slope\": np.nan, \"offset\": np.nan, \"peaks\": {}}\n",
    "            nr_unsuccessful_calibs += 1\n",
    "    \n",
    "    if nr_unsuccessful_calibs > 0 and verbosity >= -1:\n",
    "        print(f\"WARNING: {nr_unsuccessful_calibs} calibrations failed!\")\n",
    "    elif verbosity >= 0:\n",
    "        print(\"Info: All simple calibrations successful! :)\")\n",
    "\n",
    "    if draw:\n",
    "        fig.tight_layout()\n",
    "        if nodraw_axes: # have to do this also for non-drawn plots\n",
    "            for ax in ax_iter:\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "            fig.subplots_adjust(wspace=0) # , hspace=0)\n",
    "    return ret, nr_unsuccessful_calibs, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "simple_calibration(energies[\"S007\"], {\"quantile\": 0.98, \"nbins\": 200}, peakfinder_defaults,\n",
    "                   {}, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3687aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "simple_calibration(energies[\"S090\"], {\"quantile\": 0.98, \"nbins\": 200}, peakfinder_defaults | {\"double_peak\": True}, {}, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c35d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peakfinder_overrides={\n",
    "    \"S046\": {\"a_delta_min_in\": 8e-3, \"a_delta_max_in\": 8e-3,},\n",
    "    \"S015\": {\"a_delta_min_in\": 1e-2, \"a_delta_max_in\": 2e-2,},\n",
    "    \"S083\": {\"double_peak\": True},\n",
    "    \"S090\": {\"double_peak\": True},\n",
    "    \"S095\": {\"double_peak\": True},\n",
    "    \"S096\": {\"double_peak\": True, \"a_delta_min_in\": 1e-3, \"a_delta_max_in\": 1e-3,},\n",
    "    \"S098\": {\"double_peak\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_hist_defaults = {\"quantile\": 0.98, \"nbins\": 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_calib_output, _, _ = multi_simple_calibration(energies, gen_hist_defaults, peakfinder_defaults, {}, peakfinder_overrides=peakfinder_overrides, draw=True, nodraw_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdd603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibrated_histograms(energies, calib_output, range: tuple[float, float], nbins:int):\n",
    "    ret: dict[str, dict[str, np.typing.NDArray[Any]]] = {}\n",
    "    for name, energy in energies.items():\n",
    "        if name not in calib_output:\n",
    "            continue\n",
    "        c = calib_output[name][\"slope\"]\n",
    "        offset = calib_output[name][\"offset\"]\n",
    "        if np.isnan(c) or np.isnan(offset):\n",
    "            continue\n",
    "        energy_calibrated = energy * c + offset\n",
    "        n, be = gen_hist_by_range(energy_calibrated, range, nbins)\n",
    "        ret[name] = {\"n\": n, \"be\": be}\n",
    "    return ret\n",
    "\n",
    "def get_calibrated_PE_positions(calib_output) -> dict[str, dict[int, list[Any]]]:\n",
    "    ret = {}\n",
    "    for name, calib in calib_output.items():\n",
    "        ret[name] = {}\n",
    "        c = calib[\"slope\"]\n",
    "        offset = calib[\"offset\"]\n",
    "        for pe_id, peaks in calib[\"peaks\"].items():\n",
    "            ret[name][pe_id] = [p * c + offset for p in peaks]\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22026a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_histos = get_calibrated_histograms(energies, simple_calib_output, (0, 5), 200)\n",
    "_ = plot_all_pe_histograms(calibrated_histos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_calibrated_PE_positions(simple_calib_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParameter:\n",
    "    def __init__(self, init: tuple[float,float,float] | float):\n",
    "        if isinstance(init, tuple):\n",
    "            self.init = init[0]\n",
    "            self.min = init[1]\n",
    "            self.max = init[2]\n",
    "        else:\n",
    "            self.init = init\n",
    "            self.min = -np.inf\n",
    "            self.max = np.inf\n",
    "        self.result: np.float64 = np.float64(np.nan)\n",
    "    def set_result(self, result):\n",
    "        self.result = result\n",
    "\n",
    "class ModelComponent(ABC):\n",
    "    def __init__(self, params: dict[str, ModelParameter]):\n",
    "        self.params = params\n",
    "    def nr_params(self) -> int:\n",
    "        return len(self.params)\n",
    "    @abstractmethod\n",
    "    def eval(self, x, params) -> np.float64:\n",
    "        pass\n",
    "    def set_result_params(self, params):\n",
    "        for res, par in zip(params, self.params.values()):\n",
    "            par.set_result(res)\n",
    "    def get_result_params(self) -> Sequence[np.float64]:\n",
    "        return [p.result for p in self.params.values()]\n",
    "    def print_results(self) -> None:\n",
    "        for name, param in self.params.items():\n",
    "            print(name, param.result)\n",
    "        \n",
    "class Gauss(ModelComponent):\n",
    "    def __init__(self, mean, sigma, scale):\n",
    "        super().__init__({\n",
    "            \"mean\": ModelParameter(mean),\n",
    "            \"sigma\": ModelParameter(sigma),\n",
    "            \"scale\": ModelParameter(scale)\n",
    "        })\n",
    "    def eval(self, x, params):\n",
    "        return params[2] * scipy.stats.norm.pdf(x, loc=params[0], scale=params[1])\n",
    "    \n",
    "class ExpoDec(ModelComponent):\n",
    "    def __init__(self, lamb, scale):\n",
    "        super().__init__({\n",
    "            \"lamb\": ModelParameter(lamb),\n",
    "            \"scale\": ModelParameter(scale)\n",
    "        })\n",
    "    def eval(self, x, params):\n",
    "        return params[1]*np.exp(-1*params[0]*x)\n",
    "    \n",
    "class TwoHyperbole(ModelComponent):\n",
    "    def __init__(self, p0, p1, p2):\n",
    "        super().__init__({\n",
    "            \"p0\": ModelParameter(p0),\n",
    "            \"p1\": ModelParameter(p1),\n",
    "            \"p2\": ModelParameter(p2),\n",
    "        })\n",
    "    def eval(self, x, params):\n",
    "        return params[0] + params[1]/x + params[2]/(x*x)\n",
    "    \n",
    "class Linear(ModelComponent):\n",
    "    def __init__(self, p0, p1):\n",
    "        super().__init__({\n",
    "            \"p0\": ModelParameter(p0),\n",
    "            \"p1\": ModelParameter(p1),\n",
    "        })\n",
    "    def eval(self, x, params):\n",
    "        return params[0] + params[1]*x\n",
    "    \n",
    "class SumModel(ModelComponent):\n",
    "    def __init__(self, components: dict[str, ModelComponent]):\n",
    "        passed_params = {}\n",
    "        for m_name, model in components.items():\n",
    "            for p_name, param in model.params.items():\n",
    "                passed_params[m_name+\".\"+p_name] = param\n",
    "        super().__init__(passed_params)\n",
    "        self.components = components\n",
    "    def eval(self, x, params) -> np.float64:\n",
    "        curr = 0\n",
    "        ret = np.float64(0)\n",
    "        for comp in self.components.values():\n",
    "            ret += comp.eval(x, params[curr:curr+comp.nr_params()])\n",
    "            curr += comp.nr_params()\n",
    "        return ret\n",
    "\n",
    "def evaluate(model_component: ModelComponent, x, param_values: list[Any]):\n",
    "    if not isinstance(param_values, list):\n",
    "        raise ValueError(\"param_values has to be a list so it can be modified\")\n",
    "    ret = model_component.eval(x, param_values[:model_component.nr_params()])\n",
    "    del param_values[:model_component.nr_params()]\n",
    "    return ret\n",
    "\n",
    "def evaluate_at_result(model_component: ModelComponent, x):\n",
    "    return model_component.eval(x, model_component.get_result_params())\n",
    "\n",
    "def get_inits(model_components: list[ModelComponent]) -> list[float]:\n",
    "    ret = []\n",
    "    for mc in model_components:\n",
    "        for p in mc.params.values():\n",
    "            ret.append(p.init)\n",
    "    return ret\n",
    "\n",
    "def get_upper_bounds(model_components: list[ModelComponent]) -> list[float]:\n",
    "    ret = []\n",
    "    for mc in model_components:\n",
    "        for p in mc.params.values():\n",
    "            ret.append(p.max)\n",
    "    return ret\n",
    "\n",
    "def get_lower_bounds(model_components: list[ModelComponent]) -> list[float]:\n",
    "    ret = []\n",
    "    for mc in model_components:\n",
    "        for p in mc.params.values():\n",
    "            ret.append(p.min)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ef83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fittable:\n",
    "    def __init__(self, model: ModelComponent, fit_range: tuple[float, float]):\n",
    "        self.model = model\n",
    "        self.fit_range = fit_range\n",
    "    def fit(self, bin_weights, bin_centers): # raises RuntimeError if fit failed\n",
    "        fit_range_mask = (bin_centers >= self.fit_range[0]) & (bin_centers <= self.fit_range[1])\n",
    "        range_bin_weights = bin_weights[fit_range_mask]\n",
    "        range_bin_centers = bin_centers[fit_range_mask]\n",
    "        def model_fcn(x, *p):\n",
    "            params = list(p)\n",
    "            ret = evaluate(self.model, x, params)\n",
    "            assert len(params) == 0\n",
    "            return ret\n",
    "        return scipy.optimize.curve_fit(\n",
    "                model_fcn, range_bin_centers, range_bin_weights, p0=get_inits([self.model]), \n",
    "                bounds=(get_lower_bounds([self.model]), get_upper_bounds([self.model])))\n",
    "    def draw(self, ax, params, color):\n",
    "        xx = np.linspace(self.fit_range[0], self.fit_range[1], 1000)\n",
    "        ax.plot(xx, self.model.eval(xx, params), color=color)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gauss_fit_results(gausses: list[Gauss]) -> None:\n",
    "    gauss_means = [g.params[\"mean\"].result for g in gausses]\n",
    "    if len(gauss_means) < 2:\n",
    "        #raise ResultCheckError(f\"Too little nr of gausses {len(gauss_means)}\")\n",
    "        pass # there are SiPMs with only 1 gauss...\n",
    "    for i, mean in enumerate(gauss_means):\n",
    "        peak_expect = i+1\n",
    "        if mean < gausses[i].params[\"mean\"].min+0.05 or mean > gausses[i].params[\"mean\"].max-0.05:\n",
    "            raise ResultCheckError(f\"Mean of PE peak #{peak_expect} out of range: {mean}\")\n",
    "        if i > 0:\n",
    "            if abs(gauss_means[i] - gauss_means[i-1] - 1) > 0.2:\n",
    "                raise ResultCheckError(f\"Distance between mean of PE peaks {peak_expect-1},{peak_expect} too far off 1: {gauss_means[i] - gauss_means[i-1]}\")\n",
    "    for i, gauss in enumerate(gausses):\n",
    "        if gauss.params[\"sigma\"].result > 10:\n",
    "            raise ResultCheckError(f\"Sigma of PE peak {i+1} way too large: {gauss.params[\"sigma\"].result}\")\n",
    "    \n",
    "def check_bkg_fit_results(bkg_models: list[ModelComponent], fit_range: tuple[float, float]) -> None:\n",
    "    if len(bkg_models) == 0:\n",
    "        return\n",
    "    val_at_range_begin = np.sum([evaluate_at_result(mc, fit_range[0]) for mc in bkg_models])\n",
    "    val_at_range_end = np.sum([evaluate_at_result(mc, fit_range[1]) for mc in bkg_models])\n",
    "    if val_at_range_end > val_at_range_begin:\n",
    "        # probably trying to fit following peak\n",
    "        raise ResultCheckError(f\"Background model rises over range; from {val_at_range_begin} to {val_at_range_end}.\")\n",
    "\n",
    "advanced_calib_params_defaults = {\n",
    "    \"max_nr_gausspeaks\": 3,\n",
    "    \"fit_range_prePE\": 0.5,\n",
    "    \"fit_range_pastPE\": 0.8,\n",
    "    \"model\": \"combo\",\n",
    "    \"gauss_mean_range_low\": 0.5,\n",
    "    \"gauss_mean_range_high\": 0.5,\n",
    "}\n",
    "\n",
    "def advanced_calibration(\n",
    "        precalibrated_histo: dict[str, np.typing.NDArray[Any]],\n",
    "        calibrated_PE_positions: dict[int, list[Any]],\n",
    "        params: Mapping[str, Any], *,\n",
    "        ax = None, nofit=False, verbosity = 0\n",
    "        ) -> dict[str, float]:\n",
    "    \n",
    "    n = precalibrated_histo[\"n\"]\n",
    "    be = precalibrated_histo[\"be\"]\n",
    "    be_mid = (be[:-1] + be[1:]) / 2\n",
    "    assert len(be_mid) == len(be) - 1\n",
    "\n",
    "    gaussians = {}\n",
    "    for pe_id in range(1, params[\"max_nr_gausspeaks\"]+1):\n",
    "        try:\n",
    "            peaks = calibrated_PE_positions[pe_id]\n",
    "        except KeyError:\n",
    "            break # don't fit more gaussians than PE found\n",
    "        peakdiff = None\n",
    "        if len(peaks) >= 2:\n",
    "            peakdiff = np.max(peaks) - np.min(peaks)\n",
    "        max_in_range = np.max(n[(be_mid >= pe_id-0.5) & (be_mid <= pe_id+0.5)])\n",
    "        gauss = Gauss(\n",
    "            (pe_id, pe_id-params[\"gauss_mean_range_low\"], pe_id+params[\"gauss_mean_range_high\"]),\n",
    "            (peakdiff*2, peakdiff, np.inf) if peakdiff else 0.1,\n",
    "            (max_in_range/(5), 0, np.inf) # was (max_in_range/(3+pe_id*2), 0, np.inf)\n",
    "        )\n",
    "        gaussians[f\"gauss{pe_id}\"] = gauss\n",
    "\n",
    "    fit_range = (1 - params[\"fit_range_prePE\"], len(gaussians) + params[\"fit_range_pastPE\"])\n",
    "    fit_range_mask = (be_mid >= fit_range[0]) & (be_mid <= fit_range[1])\n",
    "    max_in_range = np.max(n[fit_range_mask])\n",
    "\n",
    "    fittables: list[Fittable] = []\n",
    "    \n",
    "    if params[\"model\"] == \"combo\":\n",
    "        expodec = ExpoDec((2, 0, np.inf), (max_in_range/2, 0, np.inf))\n",
    "        linear = Linear((max_in_range/100, 0, np.inf), -10)\n",
    "        #th = TwoHyperbole(max_in_range/2, 100, (0,-1,1))\n",
    "        backgrounds = {\"expodec\": expodec, \"linear\": linear}\n",
    "        \n",
    "        fittables.append(Fittable(SumModel(gaussians | backgrounds), fit_range))\n",
    "    elif params[\"model\"] == \"individual\":\n",
    "        backgrounds = {}\n",
    "        for i, gauss in enumerate(gaussians.values(), 1):\n",
    "            fittables.append(Fittable(gauss, (i-params[\"fit_range_prePE\"], i+params[\"fit_range_pastPE\"])))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid \\\"model\\\" parameter: {params['model']}\")\n",
    "\n",
    "    failure: str = \"\"\n",
    "    try:\n",
    "        try:\n",
    "            if nofit:\n",
    "                raise RuntimeError(\"No fit performed, as requested\")\n",
    "            for fi in fittables:\n",
    "                fitted_params, pcov = fi.fit(n, be_mid)\n",
    "                fi.model.set_result_params(fitted_params)\n",
    "        except RuntimeError as e:\n",
    "            for fi in fittables:\n",
    "                fi.model.set_result_params(get_inits([fi.model]))\n",
    "            failure = \"fit\"\n",
    "            raise ResultCheckError(e) from e\n",
    "        try:\n",
    "            check_gauss_fit_results(list(gaussians.values()))\n",
    "            check_bkg_fit_results(list(backgrounds.values()), fit_range)\n",
    "        except ResultCheckError as e:\n",
    "            failure = \"check\"\n",
    "            raise\n",
    "    except ResultCheckError:\n",
    "        raise\n",
    "    else:\n",
    "        #TODO: do calibration in this case!\n",
    "        if len(gaussians) >= 2: # proper calibration using 1 PE and 2 PE; getting offset\n",
    "            gain = gaussians[\"gauss2\"].params[\"mean\"].result - gaussians[\"gauss1\"].params[\"mean\"].result\n",
    "            c = 1/gain\n",
    "            offset = 1 - gaussians[\"gauss1\"].params[\"mean\"].result * c # 1pe peak at 1\n",
    "        else: # fallback: use 1 PE only\n",
    "            gain = gaussians[\"gauss1\"].params[\"mean\"].result\n",
    "            c = 1/gain\n",
    "            offset = 0\n",
    "        # runs finally (i.e. plot) before return\n",
    "        return {\"slope\": c, \"offset\": offset}\n",
    "    finally: # runs in any case; exception or not\n",
    "        if verbosity > 2:\n",
    "            for fi in fittables:\n",
    "                fi.model.print_results()\n",
    "        if ax is not None:\n",
    "            ax.stairs(n, be)\n",
    "            match failure:\n",
    "                case \"\":\n",
    "                    color=\"green\"\n",
    "                case \"fit\":\n",
    "                    color=\"red\"\n",
    "                case \"check\":\n",
    "                    color=\"orange\"\n",
    "            for fi in fittables:\n",
    "                fi.draw(ax, fi.model.get_result_params(), color)\n",
    "            ax.set_ylim(((np.min(n) if np.min(n) > 0 else 0.5)*0.9, np.max(n)*1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28720df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "SiPM = \"S095\"\n",
    "advanced_calibration(calibrated_histos[SiPM], get_calibrated_PE_positions(simple_calib_output)[SiPM], advanced_calib_params_defaults | {\"fit_range_prePE\": 0.5, \"fit_range_pastPE\": 0.6}, ax=ax, verbosity=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_advanced_calibration(calibrated_histo_dict, \n",
    "                               calibrated_PE_positions: dict[str, dict[int, list[Any]]],\n",
    "                             calibration_defaults: dict[str, Any], *,\n",
    "                             calibration_overrides: dict[str, dict[str, Any]] = {},\n",
    "                             draw = False, \n",
    "                             nodraw_axes = False, \n",
    "                             verbosity = 0\n",
    "                             ) -> tuple[dict[str, dict[str, float]], int, Figure | None]:\n",
    "    \"\"\"Performs advanced_calibration for all channels present in calibrated_histo_dict\"\"\"\n",
    "    ret = {}\n",
    "    fig = None\n",
    "    if draw:\n",
    "        fig, ax = plt.subplots(10, 6, figsize=(20,20))\n",
    "        ax_iter = iter(ax.ravel())\n",
    "    nr_unsuccessful_calibs = 0\n",
    "    for name, calibrated_histo in calibrated_histo_dict.items():\n",
    "        if draw:\n",
    "            ax = next(ax_iter)\n",
    "            ax.set_yscale(\"log\")\n",
    "            if nodraw_axes:\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "            ax.set_title(name, fontsize=10)\n",
    "        else:\n",
    "            ax = None\n",
    "        try:\n",
    "            calib_results = advanced_calibration(\n",
    "                calibrated_histo,\n",
    "                calibrated_PE_positions[name],\n",
    "                calibration_defaults | calibration_overrides.get(name, {}),\n",
    "                ax=ax,  verbosity=verbosity)\n",
    "            ret[name] = calib_results\n",
    "        except ResultCheckError as e:\n",
    "            print(f\"Calibration failed for {name}: {e}\")\n",
    "            ret[name] = {\"slope\": np.nan, \"offset\": np.nan}\n",
    "            nr_unsuccessful_calibs += 1\n",
    "    \n",
    "    if nr_unsuccessful_calibs > 0 and verbosity >= -1:\n",
    "        print(f\"WARNING: {nr_unsuccessful_calibs} calibrations failed!\")\n",
    "    elif verbosity >= 0:\n",
    "        print(\"Info: All advanced calibrations successful! :)\")\n",
    "\n",
    "    if draw:\n",
    "        fig.tight_layout()\n",
    "        if nodraw_axes: # have to do this also for non-drawn plots\n",
    "            for ax in ax_iter:\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "            fig.subplots_adjust(wspace=0) # , hspace=0)\n",
    "    return ret, nr_unsuccessful_calibs, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_calib_params_overrides = {\n",
    "    \"S040\": {\"fit_range_pastPE\": 0.9},\n",
    "    \"S050\": {\"fit_range_pastPE\": 1.1, \"gauss_mean_range_high\": 0.5, \"model\": \"individual\"},\n",
    "    \"S070\": {\"fit_range_prePE\": 0.2, \"fit_range_pastPE\": 0.5},\n",
    "    \"S080\": {\"fit_range_prePE\": 0.2, \"fit_range_pastPE\": 1.0, \"gauss_mean_range_high\": 1.5},\n",
    "    \"S083\": {\"fit_range_pastPE\": 0.5},\n",
    "    \"S085\": {\"fit_range_prePE\": 0.2},\n",
    "    \"S095\": {\"fit_range_pastPE\": 0.6},\n",
    "    \"S096\": {\"fit_range_prePE\": 0.2, \"fit_range_pastPE\": 0.4},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd69f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_calib_output, _, _ = multi_advanced_calibration(calibrated_histos, get_calibrated_PE_positions(simple_calib_output), advanced_calib_params_defaults, calibration_overrides=advanced_calib_params_overrides, draw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_calibration(calib1: dict[str, Any], calib2: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"Combines two calibration outputs. calib1 has to be the initial one (from uncalibrated to intermediate),\n",
    "    while calib2 is a recalibration, going from the intermediate to the final calibration.\n",
    "    The resulting calibration curve takes us from the uncalibrated to the final calibration.\"\"\"\n",
    "    return {\n",
    "        \"slope\": calib1[\"slope\"] * calib2[\"slope\"],\n",
    "        \"offset\": calib2[\"slope\"] * calib1[\"offset\"] + calib2[\"offset\"]\n",
    "    }\n",
    "def combine_multiple_calibrations(calib1: dict[str, dict[str, Any]], calib2: dict[str, dict[str, Any]]) -> dict[str, dict[str, Any]]:\n",
    "    \"\"\"same as combine_calibration, but loops over all SiPMs\"\"\"\n",
    "    ret = {}\n",
    "    for name in calib1.keys() & calib2.keys():\n",
    "        ret[name] = combine_calibration(calib1[name], calib2[name])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_calibrated_histos = get_calibrated_histograms(energies, combine_multiple_calibrations(simple_calib_output, advanced_calib_output), (0, 5), 200)\n",
    "_ = plot_all_pe_histograms(adv_calibrated_histos, gridx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8a1f6b",
   "metadata": {},
   "source": [
    "### And now let's chain it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccca204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_calibration_chain(\n",
    "        energies_dict: dict[str, np.typing.NDArray[Any]], *,\n",
    "        gen_hist_defaults: dict[str, Any], \n",
    "        peakfinder_defaults: dict[str, Any],\n",
    "        simple_calibration_defaults: dict[str, Any],\n",
    "        advanced_calibration_defaults: dict[str, Any],\n",
    "        gen_hist_overrides: dict[str, dict[str, Any]] = {}, \n",
    "        peakfinder_overrides: dict[str, dict[str, Any]] = {},\n",
    "        simple_calibration_overrides: dict[str, dict[str, Any]] = {},\n",
    "        advanced_calibration_overrides: dict[str, dict[str, Any]] = {},\n",
    "        plot_output_dir: str | None = None, # not drawing when None\n",
    "        plot_interactive: bool = False, # interactive plot, e.g. in jupyter notebook\n",
    "        verbosity: int = 0\n",
    "        ) -> dict[str, dict[str, float]]:\n",
    "    draw: bool = plot_output_dir is not None or plot_interactive\n",
    "    last_fig_path = \"\"\n",
    "    def store(figure: Figure | None, filebasename: str):\n",
    "        if plot_output_dir is None or figure is None:\n",
    "            return\n",
    "        last_fig_path = os.path.join(plot_output_dir, filebasename + \".pdf\")\n",
    "        figure.savefig(last_fig_path)\n",
    "    def get_hint() -> str:\n",
    "        if plot_output_dir is not None:\n",
    "            return f\"Please review {last_fig_path} for failures of individual SiPMs.\"\n",
    "        elif plot_interactive:\n",
    "            return f\"Please review the last interactive plot for failures of individual SiPMs.\"\n",
    "        else:\n",
    "            return \"Please re-run with active plotting to identify failures.\"\n",
    "\n",
    "    simple_calib_output, nr_failed_simple_calib, fig = multi_simple_calibration(\n",
    "        energies_dict, gen_hist_defaults, peakfinder_defaults, simple_calibration_defaults, \n",
    "        gen_hist_overrides = gen_hist_overrides,\n",
    "        peakfinder_overrides = peakfinder_overrides,\n",
    "        calibration_overrides=simple_calibration_overrides,\n",
    "        draw=draw,\n",
    "        verbosity=verbosity\n",
    "    )\n",
    "    store(fig, \"simple_calibration_peaks\")\n",
    "    if nr_failed_simple_calib > 0:\n",
    "        raise ValueError(f\"Simple Calibration failed for {nr_failed_simple_calib} out of {len(energies_dict)} SiPMs.\\n\" + \n",
    "                         get_hint() + \"\\nFailed histograms are drawn in red.\")\n",
    "    \n",
    "    simple_calibrated_histos = get_calibrated_histograms(\n",
    "        energies, simple_calib_output, \n",
    "        (advanced_calibration_defaults.get(\"histogram_begin\", 0), advanced_calibration_defaults.get(\"histogram_end\", 5)), \n",
    "        advanced_calibration_defaults.get(\"histogram_nbins\", 200)\n",
    "        )\n",
    "    if draw:\n",
    "        fig = plot_all_pe_histograms(simple_calibrated_histos, gridx=True)\n",
    "        store(fig, \"simple_calibration_result\")\n",
    "\n",
    "    advanced_calib_output, nr_failed_advanced_calib, fig = multi_advanced_calibration(\n",
    "        simple_calibrated_histos, get_calibrated_PE_positions(simple_calib_output), \n",
    "        advanced_calibration_defaults, \n",
    "        calibration_overrides=advanced_calibration_overrides, \n",
    "        draw=draw,\n",
    "        verbosity=verbosity)\n",
    "    store(fig, \"advanced_calibration_fits\")\n",
    "    if nr_failed_advanced_calib > 0:\n",
    "        raise ValueError(f\"Advanced Calibration failed for {nr_failed_simple_calib} out of {len(energies_dict)} SiPMs.\\n\" + \n",
    "                         get_hint() + \"\\nFailed fits are drawn in red (with initial parameters); Orange indicates failed checks.\")\n",
    "    \n",
    "    final_calib_output = combine_multiple_calibrations(simple_calib_output, advanced_calib_output)\n",
    "    if draw:\n",
    "        adv_calibrated_histos = get_calibrated_histograms(energies, final_calib_output, (0, 5), 200)\n",
    "        fig = plot_all_pe_histograms(adv_calibrated_histos, gridx=True)\n",
    "        store(fig, \"final_calibration_result\")\n",
    "    return final_calib_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_calibration_chain(\n",
    "    energies, \n",
    "    gen_hist_defaults=gen_hist_defaults, \n",
    "    peakfinder_defaults=peakfinder_defaults, \n",
    "    simple_calibration_defaults={}, \n",
    "    advanced_calibration_defaults=advanced_calib_params_defaults,\n",
    "    peakfinder_overrides=peakfinder_overrides,\n",
    "    advanced_calibration_overrides=advanced_calib_params_overrides,\n",
    "    plot_interactive=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SiPM QC Analysis",
   "language": "python",
   "name": "sipm_qc_ana"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
